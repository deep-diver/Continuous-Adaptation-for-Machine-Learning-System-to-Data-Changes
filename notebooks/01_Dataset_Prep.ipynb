{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Dataset_Prep",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will download [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset from [TensorFlow Dataset(TFDS)](https://www.tensorflow.org/datasets). The dataset is alreadly prepared as TFRecord format.\n",
        "\n",
        "We will push the downloaded dataset to a GCS bucket while keeping the directory strucutres like below.\n",
        "- gs://bucket-name/span-1/train/train.tfrecord\n",
        "- gs://bucket-name/span-1/test/test.tfrecord\n",
        "\n",
        "To proceed with the rest of the notebook you'd need a billing-enabled GCP account. "
      ],
      "metadata": {
        "id": "zyOcSJS29gkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "- Add the following rules to IAM\n",
        "  - Storage Object Admin\n",
        "  - Storage Object Creator"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "In order to access Google Cloud Platform from Colab environment, we need to login to GCP account with `gcloud init` command."
      ],
      "metadata": {
        "id": "TRIz8jbQ-MUb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!gcloud init"
      ],
      "outputs": [],
      "metadata": {
        "id": "lIYdn1woOS1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the original dataset and copy over to a GCS Bucket"
      ],
      "metadata": {
        "id": "bG-NwjjB-ioI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create Directories\n",
        "\n",
        "In this step we are going to create directories to hold to be downloaded TFRecord dataset. As an intial phase, the training and testing dataset will be stored in `span-1/train` and `span-1/test` directoreis respectively.\n",
        "\n",
        "When there will be more data with the same distribution, we can update the currently stored dataset. In this case, you should turn on the GCS's versioning feature.\n",
        "\n",
        "When there will be more data with the different distribution, we will create other directores of `span-2/test` and `span-2/test` to address data drift. In this way, we can keep data separetly for easier maintanence while handling versioning separtely for different `SPAN`s."
      ],
      "metadata": {
        "id": "FXvVVA_joPBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "TARGET_ROOT_DIR = \"cifar10\"\n",
        "TARGET_TRAIN_DIR = TARGET_ROOT_DIR + \"/span-1/train\"\n",
        "TARGET_TEST_DIR = TARGET_ROOT_DIR + \"/span-1/test\"\n",
        "\n",
        "!mkdir -p {TARGET_TRAIN_DIR}\n",
        "!mkdir -p {TARGET_TEST_DIR}"
      ],
      "outputs": [],
      "metadata": {
        "id": "XaAx0ZJ2QsGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Download CIFAR10 Dataset with TFDS"
      ],
      "metadata": {
        "id": "qt5er4ywpfGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Generate TFRecords with TFDS\n",
        "builder = tfds.builder(\"cifar10\")\n",
        "builder.download_and_prepare()"
      ],
      "outputs": [],
      "metadata": {
        "id": "dWUoW87xtuQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Copy Downloaded Dataset to the Directories that We have created"
      ],
      "metadata": {
        "id": "U3YidvVPppba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "!cp {builder.data_dir}/cifar10-train.tfrecord-00000-of-00001 {TARGET_TRAIN_DIR}/cifar10-train.tfrecord\n",
        "!cp {builder.data_dir}/cifar10-test.tfrecord-00000-of-00001 {TARGET_TEST_DIR}/cifar10-test.tfrecord"
      ],
      "outputs": [],
      "metadata": {
        "id": "bXUmXk7DQUxS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "!ls -R {TARGET_ROOT_DIR}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar10:\n",
            "span-1\n",
            "\n",
            "cifar10/span-1:\n",
            "test  train\n",
            "\n",
            "cifar10/span-1/test:\n",
            "cifar10-test.tfrecord\n",
            "\n",
            "cifar10/span-1/train:\n",
            "cifar10-train.tfrecord\n"
          ]
        }
      ],
      "metadata": {
        "id": "SkC_wyRYLWCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98aeae1b-e65f-46b2-a22e-e0f1bac58e91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Copy Local Files to the GCS Bucket"
      ],
      "metadata": {
        "id": "U7nDmdxY-rFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "#@title GCS\n",
        "#@markdown You should change these values as per your preferences. The copy operation can take ~5 minutes. \n",
        "BUCKET_PATH = \"gs://cifar10-csp-public\" #@param {type:\"string\"}\n",
        "REGION = \"us-central1\" #@param {type:\"string\"}\n",
        "\n",
        "!gsutil mb -l {REGION} {BUCKET_PATH}\n",
        "!gsutil -m cp -r {TARGET_ROOT_DIR}/* {BUCKET_PATH}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://cifar10-csp-public/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'cifar10-csp-public' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
            "Copying file://cifar10/span-1/train/cifar10-train.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://cifar10/span-1/test/cifar10-test.tfrecord [Content-Type=application/octet-stream]...\n",
            "\\ [2/2 files][133.3 MiB/133.3 MiB] 100% Done                                    \n",
            "Operation completed over 2 objects/133.3 MiB.                                    \n"
          ]
        }
      ],
      "metadata": {
        "id": "eqldz8Jkz8se",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f439f7-2a0f-44fa-e5ea-4b9091955248"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify if the files were copied over."
      ],
      "metadata": {
        "id": "UX7Gw2_h-4Pk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "!gsutil ls -R {BUCKET_PATH}/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://cifar10-csp-public/span-01/:\n",
            "\n",
            "gs://cifar10-csp-public/span-01/test/:\n",
            "gs://cifar10-csp-public/span-01/test/cifar10-test.tfrecord\n",
            "\n",
            "gs://cifar10-csp-public/span-01/train/:\n",
            "gs://cifar10-csp-public/span-01/train/cifar10-train.tfrecord\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNfP-pbowVkU",
        "outputId": "e10512bb-ed67-4d60-a71b-071bf29c7639"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with TFX's built-in function\n",
        "\n",
        "TFX provides [`calculate_splits_fingerprint_span_and_version`](https://github.com/tensorflow/tfx/blob/00571387b7b006e2ebb0c1277380e5a47d8f0ffa/tfx/components/example_gen/utils.py#L648) function which calculates and returns the current `SPAN` and `VERSION`.\n",
        "\n",
        "> Please note this section only works within GCP Vertex Notebook environment due to the authentication issue. If you know how to setup GCS access privilege for TFX, please let me know."
      ],
      "metadata": {
        "id": "1sVvSU4Alh-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tfx==1.2.0"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dw8IvNVRllqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from tfx import v1 as tfx\n",
        "from tfx.components.example_gen import utils"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xi8xgC8wZqVD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "from tfx.proto import example_gen_pb2\n",
        "\n",
        "_DATA_PATH = 'gs://cifar10-csp-public'\n",
        "\n",
        "splits = [\n",
        "  example_gen_pb2.Input.Split(name='train',\n",
        "                              pattern='span-{SPAN}/train/*'),\n",
        "  example_gen_pb2.Input.Split(name='val',\n",
        "                              pattern='span-{SPAN}/test/*')\n",
        "]\n",
        "\n",
        "_, span, version = utils.calculate_splits_fingerprint_span_and_version(_DATA_PATH, splits)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionDeniedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-27ee70994e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_splits_fingerprint_span_and_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/components/example_gen/utils.py\u001b[0m in \u001b[0;36mcalculate_splits_fingerprint_span_and_version\u001b[0;34m(input_base_uri, splits, range_config)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Find most recent span and version for this split.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     target_span, target_version = _get_target_span_version(\n\u001b[0;32m--> 706\u001b[0;31m         input_base_uri, split, range_config=range_config)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# TODO(b/162622803): add default behavior for when version spec not present.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/components/example_gen/utils.py\u001b[0m in \u001b[0;36m_get_target_span_version\u001b[0;34m(uri, split, range_config)\u001b[0m\n\u001b[1;32m    629\u001b[0m   \u001b[0mlatest_version_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_glob_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     match_span_tokens, match_span_int, match_version, match_version_int = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/dsl/io/fileio.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPathType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPathType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;34m\"\"\"Return the paths that match a glob pattern.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_get_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tfx/dsl/io/plugins/tensorflow_gfile.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPathType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPathType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         for matching_filename in _pywrap_file_io.GetMatchingFiles(\n\u001b[0;32m--> 443\u001b[0;31m             compat.as_bytes(pattern))\n\u001b[0m\u001b[1;32m    444\u001b[0m     ]\n\u001b[1;32m    445\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDeniedError\u001b[0m: Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading gs://cifar10-csp-public/"
          ]
        }
      ],
      "metadata": {
        "id": "Ma2QzXrEZuVX",
        "outputId": "0e0f2d40-e880-458b-f99d-6d72e4e05ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "UZFygbeUaccg"
      }
    }
  ]
}