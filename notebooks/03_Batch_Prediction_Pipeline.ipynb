{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "03_Batch_Prediction_Pipeline.ipynb",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep-diver/Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/blob/main/notebooks/03_Batch_Prediction_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqBUdDXK2IF"
      },
      "source": [
        "## Batch Prediction Pipeline\n",
        "\n",
        "The main purpose of this notebook is to build KFP pipeline doing the following steps\n",
        "1. Create an batch request input file (file list format) based on the files uploaded to a GCS bucket\n",
        "2. Run Batch Prediction on the trained model obtained from [02_TFX_Training_Pipeline.ipynb](https://github.com/deep-diver/Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/blob/main/notebooks/02_TFX_Training_Pipeline.ipynb)\n",
        "3. Measure the batch prediction model performance in terms of accuracy\n",
        "4. If model performance < threshold\n",
        "  - Copy the testing images to the original(previous) dataset\n",
        "  - Trigger the TFX training pipeline with original data + newly added data\n",
        "\n",
        "The functional test for batch prediction is shown in a separate notebook, [98_Batch_Prediction_Test.ipynb](https://github.com/deep-diver/Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/blob/main/notebooks/98_Batch_Prediction_Test.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuQerdmAK38q"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNC8roxxK3j5"
      },
      "source": [
        "!pip install fastdot\n",
        "!pip install tfx==1.2.0\n",
        "!pip install kfp==1.6.1\n",
        "!pip install -q --upgrade google-cloud-aiplatform\n",
        "!pip install -q --upgrade google-cloud-storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UKtYc2IK2II"
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd9CvkmRLFdu"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omrlUvFbLXsv"
      },
      "source": [
        "## Custom TFX Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zMGdk-lM7QX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "cellView": "form",
        "outputId": "0ff4fa93-2a68-4f81-912a-fd6cec2c6354"
      },
      "source": [
        "#@title\n",
        "from fastdot.core import *\n",
        "\n",
        "tfx_components = ['FileListGen', 'BatchPredictionGen', 'ModelPerformanceGen', 'PipelineTrigger']\n",
        "block = 'TFX Component Workflow'\n",
        "\n",
        "g = graph_items(seq_cluster(tfx_components, block))\n",
        "g"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pydot.Dot at 0x7f765f69c450>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"619pt\" height=\"99pt\"\n viewBox=\"0.00 0.00 619.00 99.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 95)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-95 615,-95 615,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_n6083dea8db984102a9242848a85fea29</title>\n<g id=\"a_clust1\"><a xlink:title=\"TFX Component Workflow\">\n<path fill=\"#555555\" fill-opacity=\"0.133333\" stroke=\"#000000\" d=\"M20,-8C20,-8 591,-8 591,-8 597,-8 603,-14 603,-20 603,-20 603,-71 603,-71 603,-77 597,-83 591,-83 591,-83 20,-83 20,-83 14,-83 8,-77 8,-71 8,-71 8,-20 8,-20 8,-14 14,-8 20,-8\"/>\n<text text-anchor=\"middle\" x=\"305.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">TFX Component Workflow</text>\n</a>\n</g>\n</g>\n<!-- n52a3a28223de41ffa0cf19215d4e2e95 -->\n<g id=\"node1\" class=\"node\">\n<title>n52a3a28223de41ffa0cf19215d4e2e95</title>\n<g id=\"a_node1\"><a xlink:title=\"FileListGen\">\n<path fill=\"#fcb763\" fill-opacity=\"0.168627\" stroke=\"#000000\" d=\"M88,-52C88,-52 28,-52 28,-52 22,-52 16,-46 16,-40 16,-40 16,-28 16,-28 16,-22 22,-16 28,-16 28,-16 88,-16 88,-16 94,-16 100,-22 100,-28 100,-28 100,-40 100,-40 100,-46 94,-52 88,-52\"/>\n<text text-anchor=\"middle\" x=\"58\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FileListGen</text>\n</a>\n</g>\n</g>\n<!-- n456a5b7a3a964b9eb7217ea3a7d22784 -->\n<g id=\"node2\" class=\"node\">\n<title>n456a5b7a3a964b9eb7217ea3a7d22784</title>\n<g id=\"a_node2\"><a xlink:title=\"BatchPredictionGen\">\n<path fill=\"#82ffb3\" fill-opacity=\"0.690196\" stroke=\"#000000\" d=\"M256,-52C256,-52 148,-52 148,-52 142,-52 136,-46 136,-40 136,-40 136,-28 136,-28 136,-22 142,-16 148,-16 148,-16 256,-16 256,-16 262,-16 268,-22 268,-28 268,-28 268,-40 268,-40 268,-46 262,-52 256,-52\"/>\n<text text-anchor=\"middle\" x=\"202\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">BatchPredictionGen</text>\n</a>\n</g>\n</g>\n<!-- n52a3a28223de41ffa0cf19215d4e2e95&#45;&gt;n456a5b7a3a964b9eb7217ea3a7d22784 -->\n<g id=\"edge1\" class=\"edge\">\n<title>n52a3a28223de41ffa0cf19215d4e2e95&#45;&gt;n456a5b7a3a964b9eb7217ea3a7d22784</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M100.0379,-34C108.0929,-34 116.7569,-34 125.5097,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.7944,-37.5001 135.7944,-34 125.7943,-30.5001 125.7944,-37.5001\"/>\n</g>\n<!-- nbe61a844a951492fbdd284707c81910d -->\n<g id=\"node3\" class=\"node\">\n<title>nbe61a844a951492fbdd284707c81910d</title>\n<g id=\"a_node3\"><a xlink:title=\"ModelPerformanceGen\">\n<path fill=\"#ff532a\" fill-opacity=\"0.207843\" stroke=\"#000000\" d=\"M442,-52C442,-52 316,-52 316,-52 310,-52 304,-46 304,-40 304,-40 304,-28 304,-28 304,-22 310,-16 316,-16 316,-16 442,-16 442,-16 448,-16 454,-22 454,-28 454,-28 454,-40 454,-40 454,-46 448,-52 442,-52\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ModelPerformanceGen</text>\n</a>\n</g>\n</g>\n<!-- n456a5b7a3a964b9eb7217ea3a7d22784&#45;&gt;nbe61a844a951492fbdd284707c81910d -->\n<g id=\"edge2\" class=\"edge\">\n<title>n456a5b7a3a964b9eb7217ea3a7d22784&#45;&gt;nbe61a844a951492fbdd284707c81910d</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M268.16,-34C276.5585,-34 285.2441,-34 293.8867,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"293.9927,-37.5001 303.9927,-34 293.9927,-30.5001 293.9927,-37.5001\"/>\n</g>\n<!-- nef536d93d09a43f2bbab67ef1b2ed96b -->\n<g id=\"node4\" class=\"node\">\n<title>nef536d93d09a43f2bbab67ef1b2ed96b</title>\n<g id=\"a_node4\"><a xlink:title=\"PipelineTrigger\">\n<path fill=\"#84ffb2\" fill-opacity=\"0.309804\" stroke=\"#000000\" d=\"M583,-52C583,-52 502,-52 502,-52 496,-52 490,-46 490,-40 490,-40 490,-28 490,-28 490,-22 496,-16 502,-16 502,-16 583,-16 583,-16 589,-16 595,-22 595,-28 595,-28 595,-40 595,-40 595,-46 589,-52 583,-52\"/>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PipelineTrigger</text>\n</a>\n</g>\n</g>\n<!-- nbe61a844a951492fbdd284707c81910d&#45;&gt;nef536d93d09a43f2bbab67ef1b2ed96b -->\n<g id=\"edge3\" class=\"edge\">\n<title>nbe61a844a951492fbdd284707c81910d&#45;&gt;nef536d93d09a43f2bbab67ef1b2ed96b</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M454.0506,-34C462.6448,-34 471.3384,-34 479.7481,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.8394,-37.5001 489.8394,-34 479.8394,-30.5001 479.8394,-37.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN4wUPP4Laqk"
      },
      "source": [
        "### **FileListGen Component**\n",
        "\n",
        "- `FileListGen` will produce a `file list` file that `BatchPredictionGen` will refer to perform batch prediction on Vertex AI\n",
        "- `file list` format can be found [here](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)\n",
        "\n",
        "**Spec**\n",
        "- input\n",
        "  - GCS path where the raw files are\n",
        "  - GCS path where the `file list` file will be \n",
        "- output\n",
        "  - GCS path where the `file list` file is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nit2eUyQx-Zo"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwlMeqr8qKTE"
      },
      "source": [
        "GOOGLE_CLOUD_PROJECT = 'central-hangar-321813'    #@param {type:\"string\"}\n",
        "GOOGLE_CLOUD_REGION = 'us-central1'             #@param {type:\"string\"}\n",
        "\n",
        "MODEL_NAME = 'resnet_cifar_latest' #@param {type:\"string\"}\n",
        "\n",
        "TEST_FILENAME = 'test-images.txt' #@param {type:\"string\"}\n",
        "TEST_GCS_BUCKET = 'batch-prediction-collection' #@param {type:\"string\"}\n",
        "TEST_GCS_PREFIX = '' #@param {type: \"string\"}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObPLaHx9pm6M"
      },
      "source": [
        "from google.cloud import storage"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKGOgj3KpnwV"
      },
      "source": [
        "client = storage.Client(project=GOOGLE_CLOUD_PROJECT)\n",
        "bucket = client.get_bucket(TEST_GCS_BUCKET)\n",
        "blobs = bucket.list_blobs(prefix=TEST_GCS_PREFIX)\n",
        "\n",
        "f = open(TEST_FILENAME, \"w\")\n",
        "\n",
        "for blob in blobs:\n",
        "  if blob.name.split('.')[-1] == \"jpg\":\n",
        "    if TEST_GCS_PREFIX != '':\n",
        "      TEST_GCS_PREFIX = f'/{TEST_GCS_PREFIX}'\n",
        "    line = f'{TEST_GCS_BUCKET}{TEST_GCS_PREFIX}/{blob.name}\\n'\n",
        "\n",
        "    f.write(line)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMo28z34qaHF",
        "outputId": "5c4e34b3-fcf7-4440-9efc-1039560286c5"
      },
      "source": [
        "!cat {TEST_FILENAME}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch-prediction-collection/airplane_0000.jpg\n",
            "batch-prediction-collection/automobile_0000.jpg\n",
            "batch-prediction-collection/bird_0000.jpg\n",
            "batch-prediction-collection/cat_0000.jpg\n",
            "batch-prediction-collection/deer_0000.jpg\n",
            "batch-prediction-collection/dog_0000.jpg\n",
            "batch-prediction-collection/frog_0000.jpg\n",
            "batch-prediction-collection/horse_0000.jpg\n",
            "batch-prediction-collection/ship_0000.jpg\n",
            "batch-prediction-collection/truck_0000.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Dgp0KWwWwn"
      },
      "source": [
        "blob = bucket.blob(f'test/{TEST_FILENAME}')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hVk2ma4waMd"
      },
      "source": [
        "blob.upload_from_filename(TEST_FILENAME)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRXtyTYxx6Er"
      },
      "source": [
        "#### Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5z336WGoT0q"
      },
      "source": [
        "_file_list_gen_module_file = 'file_list_gen.py'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s_YUXiFobVr",
        "outputId": "b036885c-66e8-46d6-ef54-ee34e5ea736f"
      },
      "source": [
        "%%writefile {_file_list_gen_module_file}\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.dsl.component.experimental.decorators import component\n",
        "from tfx.dsl.component.experimental.annotations import Parameter\n",
        "from google.cloud import storage\n",
        "from absl import logging\n",
        "\n",
        "@component\n",
        "def FileListGen(\n",
        "    project: Parameter[str],\n",
        "    gcs_source_bucket: Parameter[str],\n",
        "    gcs_source_prefix: Parameter[str] = '',\n",
        "    output_filename: Parameter[str] = 'test-images.txt'\n",
        ") -> tfx.dsl.components.OutputDict(outpath=str):\n",
        "  logging.info('FileListGen started')\n",
        "\n",
        "  client = storage.Client(project=project)\n",
        "  bucket = client.get_bucket(gcs_source_bucket)\n",
        "  blobs = bucket.list_blobs(prefix=gcs_source_prefix)\n",
        "  logging.info('Successfully retrieve the file(jpg) list from GCS path')\n",
        "\n",
        "  f = open(output_filename, 'w')\n",
        "  for blob in blobs:\n",
        "    if blob.name.split('.')[-1] == 'jpg':\n",
        "      prefix = ''\n",
        "      if gcs_source_prefix != '':\n",
        "        prefix = f'/{gcs_source_prefix}'\n",
        "      line = f'{gcs_source_bucket}{prefix}/{blob.name}\\n'\n",
        "      f.write(line)\n",
        "  f.close()\n",
        "  logging.info(f'Successfully created the file list file({output_filename}) in local storage')\n",
        "\n",
        "  prefix = ''\n",
        "  if gcs_source_prefix != '':\n",
        "    prefix = f'{gcs_source_prefix}/'\n",
        "  blob = bucket.blob(f'{prefix}{output_filename}')\n",
        "  blob.upload_from_filename(output_filename)\n",
        "  logging.info(f'Successfully uploaded the file list ({prefix}{output_filename})')\n",
        "\n",
        "  return {\n",
        "      'outpath': gcs_source_bucket + '/' + prefix + output_filename,\n",
        "  }"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting file_list_gen.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ3mFDaCLgUh"
      },
      "source": [
        "### BatchPredictionGen Component\n",
        "- Behaviour of `BatchPredictionGen` is similar to TFX standard component `BulkInferrer`.\n",
        "- The only difference is we don't need `Model` artifact from `Trainer` but just `model ID` that can be found in `Vertex AI Model` registry.\n",
        "- Predicted results will be fed into the `PerformanceEvaluator` component.\n",
        "\n",
        "**Spec**\n",
        "- input\n",
        "  - GCS path where the TFRecord file is\n",
        "  - model id from Vertex AI Model\n",
        "- output\n",
        "  - predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjz3oQvTLxPG"
      },
      "source": [
        "### **PerformanceEvaluator Component**\n",
        "- Calculate any performance metrics \n",
        "- Outputs if the model performance is above or below the given threshold\n",
        "\n",
        "**Spec**\n",
        "- input\n",
        "  - predictions\n",
        "  - threshold\n",
        "- output\n",
        "  - `True` or `False` by the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N79u9i-tL5Jm"
      },
      "source": [
        "### PipelineTrigger Component\n",
        "- Trigger the training pipeline based on the `True` or `False` value by the threshold\n",
        "\n",
        "**Spec**\n",
        "- input\n",
        "  - `True` or `False` by threshold\n",
        "  - pipeline name to be triggered\n",
        "  - GCS path where the pipeline spec is \n",
        "  - GCP project ID\n",
        "  - GCP region\n",
        "- output\n",
        "  - None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQNNM_Y5DNI"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnsPuwUNL4R4"
      },
      "source": [
        "GOOGLE_CLOUD_PROJECT = 'central-hangar-321813'        #@param {type:\"string\"}\n",
        "GOOGLE_CLOUD_REGION = 'us-central1'                   #@param {type:\"string\"}\n",
        "GCS_BUCKET_NAME = 'cifar10-experimental-batch-csp'    #@param {type:\"string\"}\n",
        "\n",
        "TEST_FILENAME = 'test-images.txt' #@param {type:\"string\"}\n",
        "TEST_GCS_BUCKET = 'batch-prediction-collection' #@param {type:\"string\"}\n",
        "TEST_GCS_PREFIX = '' #@param {type: \"string\"}\n",
        "\n",
        "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
        "    from absl import logging\n",
        "    logging.error('Please set all required parameters.')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOljVxpi5Xo1",
        "outputId": "933b8855-43cb-49b4-892b-097bf297779b"
      },
      "source": [
        "PIPELINE_NAME = 'continuous-adaptation-for-data-changes-batch'\n",
        "\n",
        "# Path to various pipeline artifact.\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
        "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIPELINE_ROOT: gs://cifar10-experimental-batch-csp/pipeline_root/continuous-adaptation-for-data-changes-batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eic7WtdY5iTz"
      },
      "source": [
        "!mkdir -p ./custom_components\n",
        "!touch ./custom_components/__init__.py\n",
        "!cp -r {_file_list_gen_module_file} custom_components"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf-5AjJQ5w9Z",
        "outputId": "3fe5ba17-cbb4-4bd4-dd28-d34854cbcb68"
      },
      "source": [
        "DISPLAY_NAME = \"batch-prediction-pipeline\"\n",
        "VERSION = \"tfx-1-2-0\"\n",
        "TFX_IMAGE_URI = f\"gcr.io/{GOOGLE_CLOUD_PROJECT}/{DISPLAY_NAME}:{VERSION}\"\n",
        "print(f\"URI of the custom image: {TFX_IMAGE_URI}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URI of the custom image: gcr.io/central-hangar-321813/batch-prediction-pipeline:tfx-1-2-0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvv4-FIG58P9",
        "outputId": "2c48da41-6c67-408f-ed12-4cca61868d3a"
      },
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM gcr.io/tfx-oss-public/tfx:1.2.0\n",
        "RUN mkdir -p custom_components\n",
        "COPY custom_components/* ./custom_components/\n",
        "RUN pip install --upgrade google-cloud-aiplatform google-cloud-storage"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I86iu9-76DQi"
      },
      "source": [
        "!gcloud builds submit --tag $TFX_IMAGE_URI . --timeout=15m --machine-type=e2-highcpu-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDNAaIjB6HWy"
      },
      "source": [
        "import tfx\n",
        "from tfx.orchestration.pipeline import Pipeline\n",
        "from custom_components.file_list_gen import FileListGen\n",
        "\n",
        "def _create_pipeline(\n",
        "    pipeline_name: str,\n",
        "    pipeline_root: str,\n",
        "    data_gcs_bucket: str,\n",
        "    data_gcs_prefix: str,\n",
        "    project_id: str,\n",
        "    region: str,\n",
        ") -> Pipeline :\n",
        "  filelist_gen = FileListGen(\n",
        "      project = project_id, \n",
        "      gcs_source_bucket = data_gcs_bucket,\n",
        "      gcs_source_prefix = data_gcs_prefix,\n",
        "  )\n",
        "\n",
        "  components = [\n",
        "    filelist_gen,\n",
        "  ]\n",
        "\n",
        "  return Pipeline(\n",
        "      pipeline_name=pipeline_name, \n",
        "      pipeline_root=pipeline_root,\n",
        "      components=components\n",
        "  )"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi3BobZw7JiS"
      },
      "source": [
        "import os\n",
        "import tfx\n",
        "from tfx.orchestration.kubeflow.v2.kubeflow_v2_dag_runner import KubeflowV2DagRunner\n",
        "from tfx.orchestration.kubeflow.v2.kubeflow_v2_dag_runner import KubeflowV2DagRunnerConfig\n",
        "\n",
        "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
        "\n",
        "# Important: We need to pass the custom Docker image URI to the\n",
        "# `KubeflowV2DagRunnerConfig` to take effect.\n",
        "runner = KubeflowV2DagRunner(\n",
        "    config=KubeflowV2DagRunnerConfig(default_image=TFX_IMAGE_URI),\n",
        "    output_filename=PIPELINE_DEFINITION_FILE)\n",
        "\n",
        "_ = runner.run(\n",
        "    _create_pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        data_gcs_bucket=TEST_GCS_BUCKET,\n",
        "        data_gcs_prefix=TEST_GCS_PREFIX,\n",
        "        project_id=GOOGLE_CLOUD_PROJECT,\n",
        "        region=GOOGLE_CLOUD_REGION\n",
        "    )\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "M6ofDcYP7ogx",
        "outputId": "89e22fe8-2e70-4109-fe51-040f712c70e5"
      },
      "source": [
        "from kfp.v2.google import client\n",
        "\n",
        "pipelines_client = client.AIPlatformClient(\n",
        "    project_id=GOOGLE_CLOUD_PROJECT,\n",
        "    region=GOOGLE_CLOUD_REGION,\n",
        ")\n",
        "\n",
        "_ = pipelines_client.create_run_from_job_spec(PIPELINE_DEFINITION_FILE, enable_caching=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/continuous-adaptation-for-data-changes-batch-20210918152207?project=central-hangar-321813\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3BgesEuiuJg"
      },
      "source": [
        "![img](https://i.ibb.co/521KpYm/Screen-Shot-2021-09-19-at-12-33-18-AM.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okNlX9toiu9A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}