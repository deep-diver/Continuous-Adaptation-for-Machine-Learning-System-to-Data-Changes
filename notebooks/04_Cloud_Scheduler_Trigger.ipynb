{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "04_Cloud_Scheduler_Trigger.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep-diver/Continuous-Adaptation-for-Machine-Learning-System-to-Data-Changes/blob/main/notebooks/04_Cloud_Scheduler_Trigger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_WNxUbMmgfw"
      },
      "source": [
        "# Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9JhU_tzmgfz"
      },
      "source": [
        "1. Create Pub/Sub Topic ([refer](https://github.com/sayakpaul/CI-CD-for-Model-Training/blob/main/cloud_function_trigger.ipynb))\n",
        "2. Deploy Cloud Function ([refer](https://github.com/sayakpaul/CI-CD-for-Model-Training/blob/main/cloud_function_trigger.ipynb))\n",
        "    - check if there are enough number of images in a specific GCS bucket\n",
        "3. Publish Pub/Sub Topic to trigger batch prediction pipeline ([refer](https://github.com/sayakpaul/CI-CD-for-Model-Training/blob/main/cloud_scheduler_trigger.ipynb))\n",
        "    - need pipeline JSON spec somewhere in GCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iva2o8C-mujw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A7-ml0Yt6lX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f368fdf-1a56-4440-91d3-0c766d5ed369"
      },
      "source": [
        "!pip install --upgrade -q google-cloud-scheduler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▌                            | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 20 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 71 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 81 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |███████▍                        | 10 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 20 kB 43.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 30 kB 51.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 40 kB 54.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 2.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJLNWsPamwNw"
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRkHpHnQmzof"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH4ZvM_3m397"
      },
      "source": [
        "GOOGLE_CLOUD_PROJECT = \"gcp-ml-172005\" #@param {type:\"string\"}\n",
        "GOOGLE_CLOUD_REGION = \"us-central1\"\n",
        "\n",
        "GCS_BUCKET_NAME = 'cifar10-experimental-csp2'    #@param {type:\"string\"}\n",
        "PIPELINE_NAME = \"continuous-adaptation-for-data-changes-batch\" #@param {type:\"string\"}\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME) \n",
        "PIPELINE_LOCATION = f\"{PIPELINE_ROOT}/{PIPELINE_NAME}_pipeline.json\" \n",
        "\n",
        "PUBSUB_TOPIC = f\"trigger-{PIPELINE_NAME}\" \n",
        "\n",
        "SCHEDULER_JOB_NAME = f\"scheduler-job-{PUBSUB_TOPIC}\"\n",
        "\n",
        "IMAGE_LOCATION_BUCKET = 'batch-prediction-collection-3' #@param {type:\"string\"}"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kpidhm309Ed9",
        "outputId": "fadb39ba-d84e-462d-803c-fce387229362"
      },
      "source": [
        "IMAGE_LOCATION_BUCKET"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'batch-prediction-collection-3'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3622c4BaodLT"
      },
      "source": [
        "# Create Pub/Sub Topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1RNMdR-ofBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53dac52-ab2b-49ad-d92c-eec4782fad1b"
      },
      "source": [
        "!gcloud pubsub topics create {PUBSUB_TOPIC}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic [projects/gcp-ml-172005/topics/trigger-continuous-adaptation-for-data-changes-batch].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ISbBXvoiN7"
      },
      "source": [
        "# Deploy Cloud Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeYmsiYAqroy"
      },
      "source": [
        "### Create Cloud Function Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_hJOA47prkp"
      },
      "source": [
        "!mkdir -p cloud_function\n",
        "!touch cloud_function/__init__.py"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3gLM4SQqxMa"
      },
      "source": [
        "### Create Requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-7JN3huqdEO"
      },
      "source": [
        "_cloud_function_dep = 'cloud_function/requirements.txt'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9a9myWFqj14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6ef3f5-29dc-4651-ee62-167fb95d4634"
      },
      "source": [
        "%%writefile {_cloud_function_dep}\n",
        "\n",
        "kfp==1.6.2\n",
        "google-cloud-aiplatform\n",
        "google-cloud-storage"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cloud_function/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhaDWKaRqzzH"
      },
      "source": [
        "### Create Cloud Function Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npdLDFazZX0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dead3d54-31ab-4588-bb98-ee1e6b5610cb"
      },
      "source": [
        "!pip install google-cloud-storage"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.0.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage) (4.7.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwldC4ntpD7Z"
      },
      "source": [
        "_cloud_function_file = 'cloud_function/main.py'"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59_-cyfIonqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a64145-6d64-40bc-ebaa-0f515501ad36"
      },
      "source": [
        "%%writefile {_cloud_function_file}\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import base64\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "from google.cloud import storage\n",
        "\n",
        "def get_number_of_images(storage_client, bucket, latest_directory):\n",
        "    blobs = storage_client.list_blobs(f'{bucket}/{latest_directory}')\n",
        "\n",
        "    count = 0\n",
        "    for blob in blobs:\n",
        "      if blob.name.split('.')[-1] == \"jpg\":\n",
        "        count = count+1\n",
        "\n",
        "    return count\n",
        "\n",
        "def is_there_enough_images(storage_client, bucket, threshold):\n",
        "    number_of_images = get_number_of_images(storage_client, bucket)\n",
        "    print(f'number of images = {number_of_images}')\n",
        "    return number_of_images >= threshold\n",
        "\n",
        "def get_latest_directory(storage_client, bucket):    \n",
        "    blobs = storage_client.list_blobs(bucket)\n",
        "\n",
        "    folders = list(set([os.path.dirname(blob.name) \n",
        "                        for blob in blobs \n",
        "                        if bool(re.match(\"[1-9][0-9][0-9][0-9]-[0-1][0-9]\", os.path.dirname(blob.name))) is True]))\n",
        "\n",
        "    folders.sort(key=lambda date: datetime.strptime(date, \"%Y-%m\"))\n",
        "    print(folders[0])\n",
        "    return folders[0]\n",
        "\n",
        "def trigger_pipeline(event, context):\n",
        "    # Parse the environment variables.\n",
        "    project = os.getenv(\"PROJECT\")\n",
        "    region = os.getenv(\"REGION\")\n",
        "    gcs_pipeline_file_location = os.getenv(\"GCS_PIPELINE_FILE_LOCATION\")\n",
        "    gcs_image_bucket = os.getenv(\"GCS_IMAGE_BUCKET\")\n",
        "\n",
        "    print(project)\n",
        "    print(region)\n",
        "    print(gcs_pipeline_file_location)\n",
        "    print(gcs_image_file_location)\n",
        "    \n",
        "    threshold = 100\n",
        "\n",
        "    # Check if the pipeline file exists in the provided GCS Bucket.\n",
        "    storage_client = storage.Client()\n",
        "    latest_directory = get_latest_directory(storage_client, gcs_image_bucket)\n",
        "\n",
        "    if is_there_enough_images(storage_client, gcs_image_bucket, latest_directory, threshold):\n",
        "      path_parts = gcs_pipeline_file_location.replace(\"gs://\", \"\").split(\"/\")\n",
        "      pipeline_bucket = path_parts[0]\n",
        "      pipeline_blob = \"/\".join(path_parts[1:])\n",
        "\n",
        "      pipeline_bucket = storage_client.bucket(pipeline_bucket)\n",
        "      blob = storage.Blob(bucket=pipeline_bucket, name=pipeline_blob)\n",
        "\n",
        "      if not blob.exists(storage_client):\n",
        "          raise ValueError(f\"{gcs_pipeline_file_location} does not exist.\")\n",
        "           \n",
        "      # Initialize Vertex AI API client and submit for pipeline execution.\n",
        "      api_client = AIPlatformClient(project_id=project, region=region)\n",
        "\n",
        "      response = api_client.create_run_from_job_spec(\n",
        "          job_spec_path=gcs_pipeline_file_location,\n",
        "          parameter_values={'data_gcs_prefix': latest_directory},\n",
        "          enable_caching=True,\n",
        "      )\n",
        "\n",
        "      logging.info(response)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cloud_function/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUjuI5z7rH0Z"
      },
      "source": [
        "### Deploy Cloud Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zjMovG1WyIV"
      },
      "source": [
        "!cd cloud_function"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAcMJL-9qpoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c88cd6-b3cc-457c-d93c-f4f4f1a7bb08"
      },
      "source": [
        "ENV_VARS=f\"\"\"\\\n",
        "PROJECT={GOOGLE_CLOUD_PROJECT},\\\n",
        "REGION={GOOGLE_CLOUD_REGION},\\\n",
        "GCS_PIPELINE_FILE_LOCATION={PIPELINE_LOCATION},\\\n",
        "GCS_IMAGE_BUCKET={IMAGE_LOCATION_BUCKET}\n",
        "\"\"\"\n",
        "\n",
        "!echo {ENV_VARS}"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT=gcp-ml-172005,REGION=us-central1,GCS_PIPELINE_FILE_LOCATION=gs://cifar10-experimental-csp2/pipeline_root/continuous-adaptation-for-data-changes-batch/continuous-adaptation-for-data-changes-batch_pipeline.json,GCS_IMAGE_BUCKET=batch-prediction-collection-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdw7HUcSpBU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361323d5-bfd7-48a2-8404-1c4de83453ba"
      },
      "source": [
        "BUCKET = f'gs://{GCS_BUCKET_NAME}'\n",
        "CLOUD_FUNCTION_NAME = f'trigger-{PIPELINE_NAME}-fn'\n",
        "\n",
        "!gcloud functions deploy {CLOUD_FUNCTION_NAME} \\\n",
        "    --region={GOOGLE_CLOUD_REGION} \\\n",
        "    --trigger-topic={PUBSUB_TOPIC} \\\n",
        "    --runtime=python37 \\\n",
        "    --source=cloud_function\\\n",
        "    --entry-point=trigger_pipeline\\\n",
        "    --stage-bucket={BUCKET}\\\n",
        "    --update-env-vars={ENV_VARS}"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For Cloud Build Logs, visit: https://console.cloud.google.com/cloud-build/builds;region=us-central1/0f6d0ee8-bc58-4666-b41a-86a94eb61458?project=874401645461\n",
            "availableMemoryMb: 256\n",
            "buildId: 7b13d507-174d-4e0f-ac21-a110d9dd5ce9\n",
            "buildName: projects/874401645461/locations/us-central1/builds/7b13d507-174d-4e0f-ac21-a110d9dd5ce9\n",
            "entryPoint: trigger_pipeline\n",
            "environmentVariables:\n",
            "  GCS_IMAGE_BUCKET: batch-prediction-collection-3\n",
            "  GCS_IMAGE_FILE_LOCATION: gs://batch-prediction-collection-3\n",
            "  GCS_PIPELINE_FILE_LOCATION: gs://cifar10-experimental-csp2/pipeline_root/continuous-adaptation-for-data-changes-batch/continuous-adaptation-for-data-changes-batch_pipeline.json\n",
            "  PROJECT: gcp-ml-172005\n",
            "  REGION: us-central1\n",
            "eventTrigger:\n",
            "  eventType: google.pubsub.topic.publish\n",
            "  failurePolicy: {}\n",
            "  resource: projects/gcp-ml-172005/topics/trigger-continuous-adaptation-for-data-changes-batch\n",
            "  service: pubsub.googleapis.com\n",
            "ingressSettings: ALLOW_ALL\n",
            "labels:\n",
            "  deployment-tool: cli-gcloud\n",
            "name: projects/gcp-ml-172005/locations/us-central1/functions/trigger-continuous-adaptation-for-data-changes-batch-fn\n",
            "runtime: python37\n",
            "serviceAccountEmail: gcp-ml-172005@appspot.gserviceaccount.com\n",
            "sourceArchiveUrl: gs://cifar10-experimental-csp2/us-central1-projects/gcp-ml-172005/locations/us-central1/functions/trigger-continuous-adaptation-for-data-changes-batch-fn-rlmuhcuqicpr.zip\n",
            "status: ACTIVE\n",
            "timeout: 60s\n",
            "updateTime: '2021-10-19T00:33:41.837Z'\n",
            "versionId: '11'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEZIpLjNrNe6"
      },
      "source": [
        "### See the Progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOudc6YvrPZA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c70e204-86c8-44f7-db60-60cf1985aa7b"
      },
      "source": [
        "import IPython\n",
        "\n",
        "cloud_fn_url = f\"https://console.cloud.google.com/functions/details/{GOOGLE_CLOUD_REGION}/{CLOUD_FUNCTION_NAME}\"\n",
        "html = (\n",
        "    f'See the Cloud Function details <a href=\"{cloud_fn_url}\" target=\"_blank\">here</a>.'\n",
        ")\n",
        "IPython.display.display(IPython.display.HTML(html))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Cloud Function details <a href=\"https://console.cloud.google.com/functions/details/us-central1/trigger-continuous-adaptation-for-data-changes-batch-fn\" target=\"_blank\">here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iknpM94_tnOc"
      },
      "source": [
        "# Create Cloud Scheduler's Job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dx03Q6Qt0n4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a6f937-a4fc-4a60-859c-6fef96ae4df2"
      },
      "source": [
        "!gcloud scheduler jobs create pubsub $SCHEDULER_JOB_NAME --schedule \"*/3 * * * *\" --topic $PUBSUB_TOPIC --attributes name=scheduler #every hour"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: projects/gcp-ml-172005/locations/us-central1/jobs/scheduler-job-trigger-continuous-adaptation-for-data-changes-batch\n",
            "pubsubTarget:\n",
            "  attributes:\n",
            "    name: scheduler\n",
            "  topicName: projects/gcp-ml-172005/topics/trigger-continuous-adaptation-for-data-changes-batch\n",
            "retryConfig:\n",
            "  maxBackoffDuration: 3600s\n",
            "  maxDoublings: 16\n",
            "  maxRetryDuration: 0s\n",
            "  minBackoffDuration: 5s\n",
            "schedule: '*/3 * * * *'\n",
            "state: ENABLED\n",
            "timeZone: Etc/UTC\n",
            "userUpdateTime: '2021-10-18T01:10:04Z'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmpvGa-sZ012"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}